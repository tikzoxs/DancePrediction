import tensorflow as tf 
import tensorflow_datasets as tfds
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

checkpoint_filepath = 'ckpt/'

def get_dataset_partitions_tf(ds, ds_size=107887, train_split=0.7, val_split=0.15, test_split=0.15, shuffle=True, shuffle_size=10000):
    assert (train_split + test_split + val_split) == 1
    
    if shuffle:
        # Specify seed to always have the same split distribution between runs
        ds = ds.shuffle(shuffle_size, seed=12)
    
    train_size = int(train_split * ds_size)
    val_size = int(val_split * ds_size)
    
    train_ds = ds.take(train_size)    
    val_ds = ds.skip(train_size).take(val_size)
    test_ds = ds.skip(train_size).skip(val_size)
    
    return train_ds, val_ds, test_ds

def get_dataset_size(ds):
	count = 0
	for element in ds:
		count += 1
	return count

def normalize_inputs(ds):
	input_normalizer = layers.Normalization()
	input_normalizer.adapt(np.array(ds))
	return input_normalizer

def scheduler(epoch, lr):
	if epoch < 50:
		return float(lr)
	elif epoch%5 == 0:
		return float(lr * tf.math.exp(-0.1))
	else:
		return float(lr)


# Model No.1
def create_model(): #
	inputs = keras.Input(shape=(945,), name="past_data")
	x = layers.Dense(256, activation="relu", name="dense_1")(inputs)
	x = layers.Dense(128, activation="relu", name="dense_2")(x)
	outputs = layers.Dense(63,name="predictions")(x)
	model = keras.Model(inputs=inputs, outputs=outputs)
	return model

# # Model No.2
# def create_model():
# 	inputs = keras.Input(shape=(945,), name="past_data")
# 	x = layers.Dense(128, activation="relu", name="dense_1")(inputs)
# 	x = layers.Dense(128, activation="relu", name="dense_2")(x)
# 	outputs = layers.Dense(63,name="predictions")(x)
# 	model = keras.Model(inputs=inputs, outputs=outputs)
# 	return model

# # Model No.3
# def create_model():
# 	inputs = keras.Input(shape=(945,), name="past_data")
# 	x = layers.Dense(256, activation="relu", name="dense_1")(inputs)
# 	x = layers.Dense(128, activation="relu", name="dense_2")(x)
# 	x = layers.Dense(64, activation="relu", name="dense_3")(x)
# 	outputs = layers.Dense(63,name="predictions")(x)
# 	model = keras.Model(inputs=inputs, outputs=outputs)
# 	return model

# # Model No.4 for 1 sec prediction
# def create_model():
# 	inputs = keras.Input(shape=(945,), name="past_data")
# 	x = layers.Dense(1024, activation="relu", name="dense_1")(inputs)
# 	x = layers.Dense(1024, activation="relu", name="dense_2")(x)
# 	outputs = layers.Dense(945,name="predictions")(x)
# 	model = keras.Model(inputs=inputs, outputs=outputs)
# 	return model

def predict_motion(model, past_frames):
	in_x = np.reshape(past_frames,(1,945))
	return model.predict(in_x)

dataset_path = "tfds_dataset/"
ds = tf.data.experimental.load("tfds_dataset/")
train_ds, val_ds, test_ds = get_dataset_partitions_tf(ds)

train_size = get_dataset_size(train_ds)
val_size = get_dataset_size(val_ds)
test_size = get_dataset_size(test_ds)

print(train_size,val_size,test_size)

# test_ds = test_ds.shuffle(5000).batch(32)


model = create_model()
model.load_weights(checkpoint_filepath)
model.summary()
# model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001),loss='mean_absolute_error',metrics=["mae","acc"])
# history = model.evaluate(test_ds, batch_size=32)

# countx = 0
# for element in test_ds:
# 	countx += 1
# 	x = np.array(element[0])
# 	y = np.array(element[1])
# 	in_x = np.reshape(x,(1,945))
# 	in_y = np.reshape(y,(1,63))
# 	print(model.predict(in_x))
# 	print(in_y)
# 	if(countx == 100):
# 		break

past_frames = [-2.789, 0.933, 0.695, -2.783, 1.014, 0.687, -2.802, 1.208, 0.685, -2.805, 1.431, 0.685, -2.758, 1.578, 0.658, -2.838, 1.38, 0.661, -2.968, 1.375, 0.578, -3.02, 1.114, 0.546, -2.939, 0.886, 0.502, -2.775, 1.381, 0.71, -2.668, 1.371, 0.821, -2.61, 1.111, 0.851, -2.573, 0.908, 0.796, -2.873, 0.933, 0.641, -2.879, 0.504, 0.591, -2.965, 0.094, 0.672, -2.866, 0.024, 0.562, -2.705, 0.932, 0.749, -2.658, 0.503, 0.734, -2.675, 0.079, 0.786, -2.555, 0.027, 0.689, -2.789, 0.928, 0.696, -2.786, 1.009, 0.687, -2.808, 1.205, 0.683, -2.808, 1.428, 0.682, -2.76, 1.575, 0.657, -2.843, 1.377, 0.66, -2.976, 1.375, 0.581, -3.03, 1.113, 0.568, -2.942, 0.89, 0.503, -2.778, 1.377, 0.706, -2.666, 1.369, 0.813, -2.609, 1.109, 0.852, -2.571, 0.905, 0.803, -2.874, 0.926, 0.644, -2.867, 0.499, 0.579, -2.963, 0.093, 0.67, -2.864, 0.023, 0.561, -2.704, 0.93, 0.748, -2.663, 0.501, 0.753, -2.674, 0.075, 0.79, -2.554, 0.028, 0.69, -2.788, 0.931, 0.694, -2.783, 1.013, 0.687, -2.805, 1.206, 0.683, -2.809, 1.429, 0.682, -2.763, 1.576, 0.655, -2.842, 1.378, 0.659, -2.974, 1.371, 0.579, -3.039, 1.111, 0.566, -2.947, 0.889, 0.506, -2.779, 1.379, 0.707, -2.671, 1.37, 0.818, -2.615, 1.108, 0.841, -2.57, 0.901, 0.808, -2.871, 0.932, 0.638, -2.886, 0.502, 0.602, -2.966, 0.088, 0.672, -2.865, 0.024, 0.561, -2.706, 0.93, 0.75, -2.657, 0.502, 0.732, -2.676, 0.078, 0.787, -2.556, 0.027, 0.69, -2.787, 0.93, 0.694, -2.781, 1.011, 0.688, -2.799, 1.206, 0.687, -2.808, 1.429, 0.685, -2.766, 1.577, 0.659, -2.839, 1.377, 0.661, -2.966, 1.371, 0.573, -3.04, 1.114, 0.56, -2.957, 0.886, 0.511, -2.777, 1.379, 0.711, -2.675, 1.375, 0.826, -2.622, 1.112, 0.841, -2.571, 0.908, 0.807, -2.868, 0.932, 0.635, -2.911, 0.503, 0.62, -2.968, 0.082, 0.673, -2.866, 0.025, 0.56, -2.707, 0.928, 0.753, -2.64, 0.505, 0.702, -2.678, 0.086, 0.78, -2.557, 0.024, 0.69, -2.789, 0.926, 0.693, -2.783, 1.008, 0.689, -2.796, 1.202, 0.688, -2.804, 1.425, 0.686, -2.767, 1.575, 0.661, -2.835, 1.373, 0.662, -2.962, 1.366, 0.574, -3.035, 1.108, 0.555, -2.966, 0.876, 0.512, -2.774, 1.376, 0.713, -2.671, 1.37, 0.828, -2.618, 1.108, 0.854, -2.569, 0.906, 0.807, -2.87, 0.929, 0.635, -2.909, 0.499, 0.619, -2.969, 0.079, 0.672, -2.865, 0.025, 0.559, -2.708, 0.924, 0.751, -2.642, 0.5, 0.703, -2.679, 0.082, 0.783, -2.556, 0.025, 0.691, -2.792, 0.931, 0.694, -2.787, 1.013, 0.688, -2.802, 1.208, 0.688, -2.808, 1.431, 0.688, -2.765, 1.579, 0.663, -2.841, 1.38, 0.665, -2.972, 1.374, 0.584, -3.034, 1.114, 0.567, -2.977, 0.883, 0.514, -2.777, 1.381, 0.713, -2.67, 1.374, 0.824, -2.612, 1.114, 0.858, -2.57, 0.907, 0.803, -2.875, 0.931, 0.639, -2.889, 0.502, 0.596, -2.967, 0.088, 0.672, -2.866, 0.025, 0.561, -2.709, 0.931, 0.749, -2.659, 0.503, 0.726, -2.676, 0.08, 0.786, -2.556, 0.027, 0.69, -2.796, 0.931, 0.694, -2.792, 1.012, 0.687, -2.807, 1.207, 0.687, -2.811, 1.43, 0.687, -2.773, 1.58, 0.667, -2.845, 1.379, 0.665, -2.978, 1.377, 0.587, -3.048, 1.118, 0.579, -2.98, 0.889, 0.516, -2.78, 1.38, 0.711, -2.668, 1.372, 0.818, -2.611, 1.113, 0.853, -2.57, 0.91, 0.802, -2.88, 0.93, 0.639, -2.886, 0.502, 0.589, -2.964, 0.089, 0.669, -2.863, 0.023, 0.56, -2.713, 0.931, 0.749, -2.666, 0.502, 0.749, -2.676, 0.076, 0.789, -2.554, 0.028, 0.691, -2.795, 0.929, 0.694, -2.791, 1.01, 0.688, -2.808, 1.206, 0.687, -2.813, 1.429, 0.688, -2.774, 1.578, 0.665, -2.846, 1.378, 0.665, -2.979, 1.373, 0.586, -3.057, 1.117, 0.575, -2.978, 0.889, 0.516, -2.782, 1.379, 0.712, -2.671, 1.37, 0.82, -2.614, 1.109, 0.842, -2.569, 0.905, 0.798, -2.877, 0.929, 0.637, -2.895, 0.499, 0.602, -2.968, 0.084, 0.672, -2.865, 0.025, 0.56, -2.713, 0.929, 0.751, -2.661, 0.501, 0.741, -2.677, 0.076, 0.789, -2.556, 0.028, 0.691, -2.797, 0.931, 0.696, -2.792, 1.012, 0.69, -2.805, 1.207, 0.691, -2.812, 1.43, 0.69, -2.781, 1.583, 0.675, -2.844, 1.378, 0.666, -2.974, 1.375, 0.583, -3.054, 1.119, 0.57, -2.977, 0.89, 0.517, -2.781, 1.381, 0.716, -2.674, 1.374, 0.826, -2.62, 1.111, 0.839, -2.57, 0.909, 0.793, -2.877, 0.932, 0.636, -2.911, 0.503, 0.617, -2.969, 0.082, 0.671, -2.865, 0.025, 0.559, -2.718, 0.929, 0.756, -2.649, 0.505, 0.714, -2.677, 0.085, 0.784, -2.557, 0.026, 0.69, -2.798, 0.928, 0.695, -2.793, 1.01, 0.69, -2.803, 1.205, 0.691, -2.811, 1.428, 0.691, -2.78, 1.58, 0.673, -2.842, 1.376, 0.667, -2.97, 1.372, 0.58, -3.051, 1.116, 0.566, -2.977, 0.885, 0.515, -2.781, 1.378, 0.717, -2.675, 1.37, 0.829, -2.618, 1.108, 0.848, -2.572, 0.907, 0.786, -2.878, 0.931, 0.635, -2.912, 0.501, 0.619, -2.969, 0.08, 0.673, -2.866, 0.026, 0.559, -2.718, 0.926, 0.754, -2.65, 0.502, 0.71, -2.679, 0.081, 0.782, -2.556, 0.025, 0.69, -2.802, 0.932, 0.693, -2.796, 1.013, 0.689, -2.807, 1.208, 0.69, -2.813, 1.431, 0.693, -2.777, 1.582, 0.675, -2.845, 1.38, 0.669, -2.975, 1.376, 0.585, -3.038, 1.116, 0.564, -2.976, 0.887, 0.513, -2.783, 1.381, 0.718, -2.676, 1.371, 0.829, -2.618, 1.11, 0.853, -2.576, 0.91, 0.786, -2.883, 0.934, 0.636, -2.893, 0.504, 0.6, -2.967, 0.089, 0.672, -2.866, 0.025, 0.561, -2.72, 0.93, 0.751, -2.663, 0.502, 0.736, -2.677, 0.078, 0.786, -2.556, 0.027, 0.689, -2.803, 0.929, 0.693, -2.799, 1.011, 0.687, -2.812, 1.207, 0.688, -2.816, 1.43, 0.693, -2.783, 1.582, 0.679, -2.849, 1.379, 0.669, -2.98, 1.377, 0.587, -3.041, 1.117, 0.564, -2.971, 0.889, 0.508, -2.785, 1.379, 0.716, -2.675, 1.369, 0.824, -2.616, 1.109, 0.85, -2.578, 0.908, 0.785, -2.886, 0.93, 0.636, -2.885, 0.501, 0.585, -2.967, 0.09, 0.671, -2.866, 0.024, 0.561, -2.721, 0.929, 0.749, -2.671, 0.5, 0.753, -2.675, 0.074, 0.789, -2.554, 0.028, 0.69, -2.803, 0.929, 0.692, -2.799, 1.011, 0.688, -2.813, 1.207, 0.688, -2.818, 1.43, 0.692, -2.783, 1.581, 0.677, -2.851, 1.379, 0.668, -2.98, 1.375, 0.583, -3.051, 1.117, 0.56, -2.964, 0.89, 0.502, -2.788, 1.379, 0.717, -2.679, 1.367, 0.826, -2.623, 1.105, 0.838, -2.581, 0.903, 0.785, -2.884, 0.93, 0.633, -2.898, 0.5, 0.601, -2.969, 0.084, 0.671, -2.865, 0.025, 0.56, -2.723, 0.928, 0.751, -2.665, 0.501, 0.736, -2.678, 0.077, 0.788, -2.556, 0.027, 0.691, -2.804, 0.93, 0.694, -2.799, 1.011, 0.69, -2.811, 1.208, 0.69, -2.819, 1.431, 0.693, -2.785, 1.583, 0.678, -2.85, 1.38, 0.667, -2.975, 1.377, 0.576, -3.05, 1.12, 0.55, -2.959, 0.893, 0.497, -2.789, 1.381, 0.718, -2.683, 1.372, 0.831, -2.63, 1.109, 0.837, -2.584, 0.906, 0.787, -2.883, 0.931, 0.633, -2.915, 0.501, 0.616, -2.971, 0.081, 0.672, -2.866, 0.026, 0.56, -2.725, 0.928, 0.755, -2.652, 0.504, 0.714, -2.678, 0.083, 0.783, -2.557, 0.026, 0.69, -2.804, 0.929, 0.693, -2.799, 1.01, 0.69, -2.809, 1.207, 0.69, -2.819, 1.43, 0.693, -2.785, 1.582, 0.68, -2.849, 1.378, 0.667, -2.972, 1.374, 0.574, -3.046, 1.118, 0.542, -2.957, 0.889, 0.489, -2.789, 1.38, 0.719, -2.685, 1.37, 0.833, -2.63, 1.107, 0.847, -2.587, 0.906, 0.79, -2.884, 0.931, 0.633, -2.914, 0.501, 0.616, -2.971, 0.081, 0.674, -2.867, 0.026, 0.561, -2.724, 0.926, 0.752, -2.651, 0.503, 0.713, -2.679, 0.082, 0.784, -2.557, 0.027, 0.69]

next_frame = predict_motion(model, past_frames) #past frames should be a 1-D numpy array with 945 numbers

print(next_frame)